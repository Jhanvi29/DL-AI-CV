{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyqFl1HBarLD"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "Vh9pw2P5dEFu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "oxO6DNQ-dHGt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "OYE2Uwi2dHyH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download arunrk7/surface-crack-detection\n"
      ],
      "metadata": {
        "id": "NfnHDSYWdQ21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip surface-crack-detection.zip"
      ],
      "metadata": {
        "id": "w17NQEPWdzmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "Vgx97BL8tHOf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_list = []\n",
        "for image in os.listdir('Negative'):\n",
        "  root_path = os.path.join('Negative' , image)\n",
        "  image_list.append((root_path , 0))\n",
        "\n",
        "for image in os.listdir('Positive'):\n",
        "  root_path = os.path.join('Positive' , image)\n",
        "  image_list.append((root_path , 1))\n"
      ],
      "metadata": {
        "id": "dedBwewS2BEO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in image_list :\n",
        "  print(x)\n",
        "  print(y)"
      ],
      "metadata": {
        "id": "OPzu1BGt3Xg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_dataset(Dataset):\n",
        "  def __init__(self , image_list , transform):\n",
        "    self.image_list = image_list\n",
        "    self.transform = transform\n",
        "    self.images = []\n",
        "    self.labels = []\n",
        "\n",
        "    for dir , label in image_list:\n",
        "      self.images.append(dir)\n",
        "      self.labels.append(label)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    image = Image.open(self.images[index])\n",
        "    label = self.labels[index]\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "fYH37aONd7gQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(image_list)\n",
        "train_size = len(image_list) * 0.8\n",
        "test_size = len(image_list) * 0.2\n",
        "\n",
        "print(test_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAaZX1Xcyj1k",
        "outputId": "1696bdcd-a874-4700-ebcd-45d6338d85b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
        "train_dataset = Custom_dataset(image_list[0:32000] , transform)\n",
        "test_dataset = Custom_dataset(image_list[32000 : 40000] , transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "03miiFzF0IE3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (data, labels) in enumerate(train_dataloader):\n",
        "    print(f\"Batch {batch_idx}\")\n",
        "    print(\"Data:\", data)\n",
        "    print(\"Labels:\", labels)\n",
        "    # Optionally, break after the first few batches to avoid printing too much data\n",
        "    if batch_idx == 1:  # Change this number based on how many batches you want to print\n",
        "        break"
      ],
      "metadata": {
        "id": "2CrRZBC86-_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, nc, output):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.nc = nc\n",
        "        self.output = output\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 32 * 128, 32)  # Adjust the size\n",
        "        self.fc2 = nn.Linear(32, 2)  # Assuming 2 classes: cracked and uncracked\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 32 * 32 * 128)  # Adjust the size\n",
        "        x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "N08cq2FR7plq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(32, 3 , 256, 256)\n",
        "model = Classifier(3,2)\n",
        "output = model(input)\n",
        "output.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RICTn44PcQ_1",
        "outputId": "6ee98861-f8b7-4d27-89f2-c7d76b4bb47d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool = nn.MaxPool2d(2, 2)\n",
        "c1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "c2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "c3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "o1 = pool(c1(input))\n",
        "o2 = pool(c2(o1))\n",
        "o3 = pool(c3(o2))\n",
        "\n",
        "o4 = o3.view(-1, 32 * 32 * 128)\n",
        "\n",
        "l1 = nn.Linear(32 * 32 * 128, 32)\n",
        "o5 = l1(o4)\n",
        "\n",
        "l2 = nn.Linear(32 , 2)\n",
        "o6 = l2(o5)\n",
        "\n",
        "print(o6.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxzkBbriz6ej",
        "outputId": "b044b296-1c25-4976-877e-40b843865a1d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(3,2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define the cross-entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Assuming you're using GPU (CUDA)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for iter in range(5):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, labels) in enumerate(train_dataloader):\n",
        "        # Move data and labels to the GPU\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Accumulate loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print statistics for this iteration\n",
        "    print(f'Iteration {iter + 1}:')\n",
        "    print(f'Loss: {running_loss / len(train_dataloader):.4f}')\n",
        "    print(f'Accuracy: {(correct / total) * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-hQXlcWyzz-",
        "outputId": "1fd89990-cda4-47fc-fd70-8bc1711d3799"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1:\n",
            "Loss: 0.4890\n",
            "Accuracy: 75.06%\n",
            "Iteration 2:\n",
            "Loss: 0.1247\n",
            "Accuracy: 96.20%\n",
            "Iteration 3:\n",
            "Loss: 0.0818\n",
            "Accuracy: 97.69%\n",
            "Iteration 4:\n",
            "Loss: 0.0668\n",
            "Accuracy: 98.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()  # Use the appropriate loss function\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "test_loss = 0.0  # Initialize the test loss\n",
        "correct = 0  # Initialize the number of correct predictions\n",
        "total = 0  # Initialize the total number of samples\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    for data, labels in test_dataloader:\n",
        "        data = data.to(device)  # Move data to the GPU if available\n",
        "        labels = labels.to(device)  # Move labels to the GPU if available\n",
        "\n",
        "        outputs = model(data)  # Get model predictions\n",
        "        loss = criterion(outputs, labels)  # Calculate the loss\n",
        "\n",
        "        test_loss += loss.item()  # Accumulate the loss\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest probability\n",
        "        total += labels.size(0)  # Increment the total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
        "\n",
        "# Calculate the average test loss\n",
        "average_loss = test_loss / len(test_dataloader)\n",
        "accuracy = 100.0 * correct / total\n",
        "\n",
        "print(f'Test Loss: {average_loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAWoT_IC9a80",
        "outputId": "dce46210-e982-4e81-f548-962af374dd90"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0895\n",
            "Test Accuracy: 97.83%\n"
          ]
        }
      ]
    }
  ]
}