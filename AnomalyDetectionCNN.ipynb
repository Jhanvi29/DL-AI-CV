{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ELyZbl2j6Q",
        "outputId": "2f08c08e-9895-47da-d9ff-fc7e3d7663b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctEchiPX3BJl"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6FYZBY43DCI"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhOR-y1N3Hs0"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGELrMIc3V-F",
        "outputId": "f7c6490b-c263-4b5a-f874-a7c07eb1bad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chest-xray-pneumonia.zip to /content\n",
            " 99% 2.28G/2.29G [01:00<00:00, 48.2MB/s]\n",
            "100% 2.29G/2.29G [01:00<00:00, 41.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTlwg9P93gsh"
      },
      "outputs": [],
      "source": [
        "!unzip chest-xray-pneumonia.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch import nn,optim\n",
        "from torchvision import transforms as T,datasets,models\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import OrderedDict\n",
        "from tqdm import tqdm\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "3-EolYYV2clY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0t5VjBMN2fgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_transforms(phase = None):\n",
        "\n",
        "    if phase == TRAIN:\n",
        "\n",
        "        data_T = T.Compose([\n",
        "\n",
        "                T.Resize(size = (256,256)),\n",
        "                T.RandomRotation(degrees = (-20,+20)),\n",
        "                T.CenterCrop(size=224),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    elif phase == TEST or phase == VAL:\n",
        "\n",
        "        data_T = T.Compose([\n",
        "\n",
        "                T.Resize(size = (224,224)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    return data_T"
      ],
      "metadata": {
        "id": "aytPSsHg2YCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"chest_xray\"\n",
        "TEST = 'test'\n",
        "TRAIN = 'train'\n",
        "VAL ='val'\n",
        "\n",
        "trainset = datasets.ImageFolder(os.path.join(data_dir, TRAIN),transform = data_transforms(TRAIN))\n",
        "testset = datasets.ImageFolder(os.path.join(data_dir, TEST),transform = data_transforms(TEST))\n",
        "validset = datasets.ImageFolder(os.path.join(data_dir, VAL),transform = data_transforms(VAL))"
      ],
      "metadata": {
        "id": "cokmnnok2gON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset,batch_size = 64,shuffle = True)\n",
        "validloader = DataLoader(validset,batch_size = 64,shuffle = True)\n",
        "testloader = DataLoader(testset,batch_size = 64,shuffle = True)\n",
        "\n",
        "images, labels = iter(trainloader).next()\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGX5gqmT2lkp",
        "outputId": "1e70335a-dbf0-41a8-8114-8db80a300bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 224, 224])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (images,labels) in enumerate(trainloader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())"
      ],
      "metadata": {
        "id": "UCBVb3__2o-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class classify(nn.Module):\n",
        "    def __init__(self,num_classes=2):\n",
        "        super(classify,self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        self.relu2=nn.ReLU()\n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        self.relu3=nn.ReLU()\n",
        "        self.fc=nn.Linear(in_features=32 * 112 * 112,out_features=num_classes)\n",
        "\n",
        "\n",
        "\n",
        "        #Feed forwad function\n",
        "\n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "        output=self.pool(output)\n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "        output=output.view(-1,32*112*112)\n",
        "        output=self.fc(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TIhybYyN2tmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = classify()\n",
        "# defining the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "# defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "metadata": {
        "id": "nqLrSSE32wLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Losses = []\n",
        "for i in range(10):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "\n",
        "        #Changing images to cuda for gpu\n",
        "        if torch.cuda.is_available():\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "\n",
        "        # Training pass\n",
        "        # Sets the gradient to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        #This is where the model learns by backpropagating\n",
        "        # accumulates the loss for mini batch\n",
        "        loss.backward()\n",
        "\n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        Losses.append(loss)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(trainloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fru7wCIv2zZh",
        "outputId": "5c817972-8553-44fe-964e-818d915903b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Training loss: 67.54923639064882\n",
            "Epoch 2 - Training loss: 8.892776101464179\n",
            "Epoch 3 - Training loss: 8.870187003438065\n",
            "Epoch 4 - Training loss: 3.651566917207946\n",
            "Epoch 5 - Training loss: 2.0226034194049314\n",
            "Epoch 6 - Training loss: 1.2094495241158367\n",
            "Epoch 7 - Training loss: 0.4696524849582269\n",
            "Epoch 8 - Training loss: 0.3544137337977612\n",
            "Epoch 9 - Training loss: 0.24045869335532188\n",
            "Epoch 10 - Training loss: 0.1926852000718255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count, all_count = 0, 0\n",
        "for images,labels in testloader:\n",
        "  for i in range(len(labels)):\n",
        "    if torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "    img = images[i].view(1, 3, 224, 224)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.cpu()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdo4Hgk92211",
        "outputId": "13304911-2a18-4c35-f52e-1ab2aa09085f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Of Images Tested = 624\n",
            "\n",
            "Model Accuracy = 0.7564102564102564\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}